---
title: Monitoring & Observability
description: Structured logging, Prometheus-style metrics, and troubleshooting for production tollbooth deployments.
keywords:
  - monitoring
  - observability
  - metrics
  - logging
  - Prometheus
  - Grafana
  - structured logs
  - request ID
  - latency
  - 402
  - rate limiting
  - cache
  - troubleshooting
---

tollbooth emits structured JSON logs for every request. This guide covers the log fields you should index, the metrics you should track, and how to diagnose common production issues.

## Structured log fields

Every log line tollbooth produces is a JSON object. The fields below are the most useful for filtering, alerting, and dashboarding.

| Field | Type | Description |
|---|---|---|
| `request_id` | `string` | Unique ID for the request. Propagated from incoming `X-Request-Id` header, or generated by tollbooth. |
| `route_id` | `string` | Matched route pattern, e.g. `GET /v1/messages`. |
| `upstream_id` | `string` | Name of the upstream that handled the request. |
| `client_id` | `string` | Payer address or identity key extracted from the payment header. |
| `price` | `string` | Price charged for the route, e.g. `"$0.01"`. |
| `session_id` | `string` | x402 session identifier, if present. |
| `settlement_strategy` | `string` | Strategy used: `facilitator`, `mock`, or custom. |
| `settlement_id` | `string` | On-chain transaction hash or settlement reference. |
| `cache_hit` | `boolean` | Whether the payment verification was served from cache. |
| `rl_decision` | `string` | Rate-limit outcome: `allowed`, `throttled`, or `blocked`. |
| `latency_ms` | `number` | Total request duration in milliseconds. |
| `status` | `number` | HTTP status code returned to the client. |
| `settlement_latency_ms` | `number` | Time spent on settlement alone. |
| `upstream_latency_ms` | `number` | Time spent waiting for the upstream response. |
| `error` | `string` | Error message, if any. |

### Example log lines

**Successful paid request:**

```json
{
  "level": "info",
  "request_id": "req_abc123",
  "route_id": "POST /v1/messages",
  "upstream_id": "anthropic",
  "client_id": "0x1234...abcd",
  "price": "$0.075",
  "settlement_strategy": "facilitator",
  "settlement_id": "0xdeadbeef...",
  "cache_hit": false,
  "rl_decision": "allowed",
  "status": 200,
  "latency_ms": 342,
  "settlement_latency_ms": 187,
  "upstream_latency_ms": 148
}
```

**402 — missing payment:**

```json
{
  "level": "warn",
  "request_id": "req_def456",
  "route_id": "GET /data",
  "upstream_id": "internal-api",
  "client_id": null,
  "price": "$0.01",
  "status": 402,
  "latency_ms": 3,
  "error": "missing X-402-Payment header"
}
```

**Rate-limited request:**

```json
{
  "level": "warn",
  "request_id": "req_ghi789",
  "route_id": "POST /v1/messages",
  "client_id": "0x1234...abcd",
  "rl_decision": "blocked",
  "status": 429,
  "latency_ms": 1
}
```

## Request ID correlation

tollbooth propagates request IDs for end-to-end tracing:

1. If the incoming request has an `X-Request-Id` header, tollbooth uses it.
2. Otherwise, tollbooth generates a `req_` prefixed UUID.
3. The ID is forwarded to the upstream in `X-Request-Id`.
4. The same ID appears in the response header and in every log line for that request.

This lets you correlate a single request across tollbooth logs, upstream API logs, and client-side traces.

## Prometheus-style metrics

Expose these counters, histograms, and gauges for alerting and dashboarding. Names follow the `tollbooth_` prefix convention.

### Counters

| Metric | Labels | Description |
|---|---|---|
| `tollbooth_requests_total` | `route`, `method`, `status` | Total requests by route, method, and HTTP status. |
| `tollbooth_payments_total` | `route`, `outcome` | Payment attempts. `outcome` = `success`, `rejected`, `missing`. |
| `tollbooth_settlements_total` | `strategy`, `outcome` | Settlement attempts. `outcome` = `success`, `failure`. |
| `tollbooth_cache_hits_total` | `route` | Verification cache hits. |
| `tollbooth_cache_misses_total` | `route` | Verification cache misses. |
| `tollbooth_rate_limit_blocks_total` | `route`, `client_id` | Requests blocked by rate limiting. |
| `tollbooth_upstream_errors_total` | `upstream`, `status` | Non-2xx responses from upstreams. |

### Histograms

| Metric | Labels | Description |
|---|---|---|
| `tollbooth_request_duration_seconds` | `route`, `method` | End-to-end request latency. |
| `tollbooth_settlement_duration_seconds` | `strategy` | Settlement latency. |
| `tollbooth_upstream_duration_seconds` | `upstream` | Upstream response latency. |

### Gauges

| Metric | Labels | Description |
|---|---|---|
| `tollbooth_active_requests` | — | Currently in-flight requests. |

## Dashboards you want

If you're using Grafana (or any Prometheus-compatible dashboarding tool), these are the panels worth setting up:

### Traffic overview

- **Request rate** — `rate(tollbooth_requests_total[5m])` broken down by `route`.
- **402 rate** — `rate(tollbooth_requests_total{status="402"}[5m])`. A spike means clients aren't sending payment headers. Check if a client library updated or a route price changed.
- **Error rate** — `rate(tollbooth_requests_total{status=~"5.."}[5m])` by `route`. Upstream failures vs. tollbooth errors.

### Payments & settlement

- **Settlement success rate** — `rate(tollbooth_settlements_total{outcome="success"}[5m]) / rate(tollbooth_settlements_total[5m])`. Alert if this drops below 99%.
- **Settlement latency p95** — `histogram_quantile(0.95, rate(tollbooth_settlement_duration_seconds_bucket[5m]))`. Facilitator latency over 500 ms warrants investigation.
- **Payment rejection rate** — `rate(tollbooth_payments_total{outcome="rejected"}[5m])`. Rejections mean invalid signatures or insufficient funds.

### Cache & rate limiting

- **Cache hit ratio** — `rate(tollbooth_cache_hits_total[5m]) / (rate(tollbooth_cache_hits_total[5m]) + rate(tollbooth_cache_misses_total[5m]))`. A high miss rate increases settlement load.
- **Rate-limit blocks** — `rate(tollbooth_rate_limit_blocks_total[5m])` by `client_id`. Identify abusive clients.

### Upstream health

- **Upstream latency p95** — `histogram_quantile(0.95, rate(tollbooth_upstream_duration_seconds_bucket[5m]))` by `upstream`.
- **Upstream error rate** — `rate(tollbooth_upstream_errors_total[5m])` by `upstream` and `status`.

## Troubleshooting checklist

### High 402 rate

1. Check if clients are sending the `X-402-Payment` header.
2. Verify the route price hasn't changed unexpectedly — `grep price tollbooth.config.yaml`.
3. Check if the x402 discovery endpoint is reachable: `curl https://your-tollbooth/.well-known/x402`.
4. Look at log lines with `status: 402` — the `error` field tells you exactly why.

### Settlement failures

1. Check `tollbooth_settlements_total{outcome="failure"}` for the affected strategy.
2. For `facilitator` strategy: is the facilitator endpoint reachable? `curl https://x402.org/facilitator/health`.
3. Look at `settlement_latency_ms` — timeouts may indicate network issues.
4. Check for `error` fields containing `settlement` in recent logs.

### High upstream latency

1. Compare `upstream_latency_ms` with `latency_ms` — if they're close, tollbooth isn't the bottleneck.
2. Check the upstream's own status page or health endpoint.
3. Look for `upstream_errors_total` spikes that coincide with latency increases.

### Low cache hit rate

1. Verify that verification caching is enabled in your config.
2. Check if clients are sending unique payment tokens per request (expected for fresh payments, but repeated verifications should hit cache).
3. A restart clears the in-memory cache — frequent restarts will reduce hit rate.

### Rate-limit blocks affecting legitimate traffic

1. Review the rate-limit config for the affected route.
2. Check `client_id` in the blocked requests — is it a single heavy client or many?
3. Consider per-client rate limits instead of global limits if traffic patterns are uneven.

---

**Next:** [Refund Protection →](/guides/refund-protection/)
